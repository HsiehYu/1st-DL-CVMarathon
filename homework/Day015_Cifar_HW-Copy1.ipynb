{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 20s 0us/step\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0, 1, 2, 3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test, mean_train, std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 142s 3ms/step - loss: 1.6700 - acc: 0.3913\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 141s 3ms/step - loss: 1.2123 - acc: 0.5539\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 142s 3ms/step - loss: 0.9858 - acc: 0.6434\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 147s 3ms/step - loss: 0.8560 - acc: 0.6915\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.7526 - acc: 0.7301\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 141s 3ms/step - loss: 0.6585 - acc: 0.7630\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.5760 - acc: 0.7909\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.5012 - acc: 0.8181\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.4378 - acc: 0.8433\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.3791 - acc: 0.8642\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.3247 - acc: 0.8831\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.2882 - acc: 0.8974\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.2439 - acc: 0.9114\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.2131 - acc: 0.9238\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.2013 - acc: 0.9262\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.1703 - acc: 0.9389\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.1534 - acc: 0.9444\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.1410 - acc: 0.9496\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.1307 - acc: 0.9525\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.1209 - acc: 0.9564\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.1189 - acc: 0.9572\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.1086 - acc: 0.9614\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 142s 3ms/step - loss: 0.0954 - acc: 0.9660\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.1037 - acc: 0.9637\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0962 - acc: 0.9667\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0864 - acc: 0.9696\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0855 - acc: 0.9696\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0782 - acc: 0.9724\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0814 - acc: 0.9711\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0794 - acc: 0.9723\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0679 - acc: 0.9765\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0707 - acc: 0.9759\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0634 - acc: 0.9776\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0642 - acc: 0.9778\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0762 - acc: 0.9737\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0634 - acc: 0.9782\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0537 - acc: 0.9822\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0615 - acc: 0.9780\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0686 - acc: 0.9758\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0587 - acc: 0.9800\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0484 - acc: 0.9833\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0590 - acc: 0.9797\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0556 - acc: 0.9807\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0520 - acc: 0.9824\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0524 - acc: 0.9821\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0437 - acc: 0.9852\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0457 - acc: 0.9843\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0455 - acc: 0.9850\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0542 - acc: 0.9819\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0481 - acc: 0.9834\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0426 - acc: 0.9852\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0383 - acc: 0.9871\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0408 - acc: 0.9861\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0517 - acc: 0.9834\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0409 - acc: 0.9863\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0430 - acc: 0.9853\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0431 - acc: 0.9861\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0363 - acc: 0.9877\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0429 - acc: 0.9855\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0434 - acc: 0.9853\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0392 - acc: 0.9869\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0307 - acc: 0.9902\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0305 - acc: 0.9898\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0385 - acc: 0.9875\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0360 - acc: 0.9874\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0362 - acc: 0.9876\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0380 - acc: 0.9875\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0332 - acc: 0.9889\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0317 - acc: 0.9891\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0320 - acc: 0.9891\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0302 - acc: 0.9899\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0378 - acc: 0.9875\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0306 - acc: 0.9899\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0257 - acc: 0.9914\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0353 - acc: 0.9886\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0297 - acc: 0.9895\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0307 - acc: 0.9899\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0250 - acc: 0.9911\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0378 - acc: 0.9868\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0313 - acc: 0.9897\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0279 - acc: 0.9905\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0203 - acc: 0.9931\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0281 - acc: 0.9906\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0332 - acc: 0.9886\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0344 - acc: 0.9890\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0275 - acc: 0.9906\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0210 - acc: 0.9931\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0215 - acc: 0.9926\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0293 - acc: 0.9901\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0332 - acc: 0.9887\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0264 - acc: 0.9911\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0213 - acc: 0.9930\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0249 - acc: 0.9916\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0238 - acc: 0.9923\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0317 - acc: 0.9891\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0245 - acc: 0.9912\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0192 - acc: 0.9938\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0238 - acc: 0.9921\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 140s 3ms/step - loss: 0.0188 - acc: 0.9936\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.0283 - acc: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28192ec2fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(units=28, activation='relu', )) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3937567e-04, 4.8708970e-09, 1.5378554e-07, 4.3474391e-01,\n",
       "        5.6511599e-01, 8.1464691e-10, 5.9032482e-07, 4.0687323e-16,\n",
       "        1.7924121e-09, 5.8031592e-18]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
